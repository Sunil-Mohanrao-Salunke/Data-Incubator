---
title: 'Data Incubator: R Notebook'
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---


```{r}
#question: What proportion of FDNY responses in this dataset correspond to the most common type of incident?
library(tidyverse)

#Read data
incidents <- read_csv("Incidents_Responded_to_by_Fire_Companies.csv")

#Check if data is loaded properly
head(incidents)

#Calculate highest Frequency
incidents %>%
  select(INCIDENT_TYPE_DESC) %>% 
  group_by(INCIDENT_TYPE_DESC) %>% 
  summarise(count.incident = n()) %>% 
  mutate(relative.freq = format(round((count.incident/sum(count.incident)), 10), nsmall = 10)) %>% 
  arrange(desc(relative.freq))
```

```{r}
#question: How many times more likely is an incident in Staten Island a false call compared to in Manhattan? 
false_calls_island <- incidents %>%
  select(BOROUGH_DESC,INCIDENT_TYPE_DESC) %>% 
  filter(str_detect(BOROUGH_DESC,"Staten Island")) %>% 
  filter(INCIDENT_TYPE_DESC == "710 - Malicious, mischievous false call, other") %>%
  count()

total_calls_island <- incidents %>% 
  select(BOROUGH_DESC, INCIDENT_TYPE_DESC) %>% 
  filter(str_detect(BOROUGH_DESC, "Staten Island")) %>% 
  count()

false_rate_island = format(round(false_calls_island / total_calls_island, 10), nsmall =10)
false_rate_island <- as.double(false_rate_island)

false_calls_Manhattan <- incidents %>%
  select(BOROUGH_DESC,INCIDENT_TYPE_DESC) %>% 
  filter(str_detect(BOROUGH_DESC,"Manhattan")) %>% 
  filter(INCIDENT_TYPE_DESC == "710 - Malicious, mischievous false call, other") %>%
  count()

total_calls_Manhattan <- incidents %>% 
  select(BOROUGH_DESC, INCIDENT_TYPE_DESC) %>% 
  filter(str_detect(BOROUGH_DESC, "Manhattan")) %>% 
  count()

false_rate_Manhattan = format(round(false_calls_Manhattan / total_calls_Manhattan, 10), nsmall=10)
false_rate_Manhattan <- as.double(false_rate_Manhattan)

(ratio = format(round(false_rate_island/false_rate_Manhattan,10), nsmall=9))
```

```{r}
#question: Compute what proportion of all incidents are cooking fires for every hour of the day by normalizing the number of cooking fires in a given hour by the total number of incidents that occured in that hour. Find the hour of the day that has the highest proportion of cooking fires and submit that proportion of cooking fires.
library(lubridate)

incidents %>% 
  select(INCIDENT_DATE_TIME, INCIDENT_TYPE_DESC) %>%
  filter(INCIDENT_TYPE_DESC == "113 - Cooking fire, confined to container") %>% 
  mutate(date_time = mdy_hms(INCIDENT_DATE_TIME)) %>% 
  mutate(hour_incident = hour(date_time)) %>% 
  group_by(hour_incident) %>% 
  summarise(cooking_fire_incidents = n()) %>% 
  inner_join(incidents %>%
               select(INCIDENT_DATE_TIME, INCIDENT_TYPE_DESC) %>%
               mutate(date_time = mdy_hms(INCIDENT_DATE_TIME)) %>% 
               mutate(hour_incident = hour(date_time)) %>% 
               group_by(hour_incident) %>% 
               summarise(total_incidents = n()), by = "hour_incident") %>% 
  mutate(cooking_fire_incident_ratio = format(round(cooking_fire_incidents/total_incidents, 10), nsmall = 10)) %>% 
  arrange(desc(cooking_fire_incident_ratio))
```

```{r}
#question: only consider incidents that have information about whether a CO detector was present or not. For events with CO detector and for those without one, compute the proportion of incidents that lasted 20-30, 30-40, 40-50, 50-60, and 60-70 minutes (both interval boundary values included) by dividing the number of incidents in each time interval with the total number of incidents. For each bin, compute the ratio of the 'CO detector absent' frequency to the 'CO detector present' frequency. Perform a linear regression of this ratio to the mid-point of the bins. From this, what is the predicted ratio for events lasting 39 minutes?

#co detector present
co_detector_present_freq <- incidents %>%
  filter(!is.na(CO_DETECTOR_PRESENT_DESC)) %>%
  filter(CO_DETECTOR_PRESENT_DESC == "Yes") %>%
  mutate(total_incident_duration_min = TOTAL_INCIDENT_DURATION/60) %>% 
  group_by(groups_duration = cut(total_incident_duration_min,breaks = c(20,30,40,50,60,70), include.lowest = TRUE)) %>%
  filter(!is.na(groups_duration)) %>% 
  summarise(co_detector_present_count = n()) %>% 
  mutate(co_detector_present_freq = co_detector_present_count / sum(co_detector_present_count))

#Frequency of co detector present in each group
co_detector_present_freq

#co detector absent
co_detector_absent_freq <- incidents %>%
  filter(!is.na(CO_DETECTOR_PRESENT_DESC)) %>%
  filter(CO_DETECTOR_PRESENT_DESC == "No") %>%
  mutate(total_incident_duration_min = TOTAL_INCIDENT_DURATION/60) %>% 
  group_by(groups_duration = cut(total_incident_duration_min,breaks = c(20,30,40,50,60,70), include.lowest = TRUE)) %>%
  filter(!is.na(groups_duration)) %>% 
  summarise(co_detector_absent_count = n()) %>%
  mutate(co_detector_absent_freq = co_detector_absent_count / sum(co_detector_absent_count))

#Frequency of co detector absent in each group
co_detector_absent_freq

proportions_co <- co_detector_present_freq %>%
  left_join(co_detector_absent_freq, by = "groups_duration") %>% 
  mutate(proportion_incidents = co_detector_absent_freq/co_detector_present_freq) %>%
  select(proportion_incidents,groups_duration)

#Proportion incidents along with groups mid points
proportions_co$group.mid <- nrow(proportions_co)
proportions_co$group.mid <- c(25,35,45,55,65)

#let's replace groups with midpoints before building linear regression model
lm_model <- lm(proportion_incidents~group.mid, data = proportions_co)
summary(lm_model)

#Let's predicted ratio for events lasting 39 minutes
prediction <- predict(lm_model, newdata = data.frame(group.mid = 39))
format(round(prediction,10), nsmall = 9)
```

```{r}
#question: What is the ratio of the average number of units that arrive to a scene of an incident classified as '111 - Building fire' to the number that arrive for '651 - Smoke scare, odor of smoke'?
#average number of units that arrive to a scene of an incident classified as '111 - Building fire'
avg_units_111 <- incidents %>% 
  filter(INCIDENT_TYPE_DESC == "111 - Building fire") %>% 
  summarise(avg.units = mean(UNITS_ONSCENE, na.rm = TRUE))
avg_units_111

#average number of units that arrive for '651 - Smoke scare, odor of smoke'
avg_units_651 <- incidents %>% 
  filter(INCIDENT_TYPE_DESC == "651 - Smoke scare, odor of smoke") %>% 
  summarise(avg.units = mean(UNITS_ONSCENE, na.rm = TRUE))
avg_units_651

#Ratio
(ratio_avg_units <- format(round(avg_units_111/avg_units_651,10), nsmall =9))

```

```{r}
# question: Check the distribution of the number of min. it takes between the time a '111 - Building fire' incident has been logged into system and the time at which the first unit arrives on scene. What is the third quartile of distribution.
incident.time <- incidents %>% 
  filter(INCIDENT_TYPE_DESC == "111 - Building fire") %>% 
  mutate(incident_dt_tm = mdy_hms(INCIDENT_DATE_TIME)) %>% 
  select(incident_dt_tm)

arrival.time <- incidents %>% 
  filter(INCIDENT_TYPE_DESC == "111 - Building fire") %>% 
  mutate(arrival_dt_tm = mdy_hms(ARRIVAL_DATE_TIME)) %>% 
  select(arrival_dt_tm)

#let's create interval object
elapsed_time <- incident.time$incident_dt_tm %--% arrival.time$arrival_dt_tm

#Duration in minutes from interval object
duration_object <- as.duration(elapsed_time)/dminutes(1)

format(round(quantile(duration_object, na.rm = TRUE)[4], 10), nsmall = 9)
```

```{r}
#question : What is the coefficient of determination (R squared) between the number of residents at each zip code and the number of inicidents whose type is classified as '111 - Building fire' at each of those zip codes.
census_data <- read_csv("2010+Census+Population+By+Zipcode+(ZCTA).csv")
colnames(census_data) <- c("Zip_Code_ZCTA", "2010_Census_population")

#let's convert zip_code type from integer to character in FDNY dataset because zip_code values are stored as character in census dataset.
incidents$ZIP_CODE <- as.character(incidents$ZIP_CODE)

#Join census data and FDNY dataset
residents_fire_data <- census_data %>% 
  left_join(incidents %>% 
              select(INCIDENT_TYPE_DESC, ZIP_CODE) %>% 
              filter(INCIDENT_TYPE_DESC == "111 - Building fire" ) %>% 
              group_by(ZIP_CODE) %>% 
              summarise(incident_111_building_fire_count = n()), by = c("Zip_Code_ZCTA" = "ZIP_CODE")) %>% 
  filter(!is.na(incident_111_building_fire_count))

#build regression model
lm_model_residents_fire <- lm(incident_111_building_fire_count ~ `2010_Census_population`, data = residents_fire_data)
#r squared value
format(round(summary(lm_model_residents_fire)$r.squared,10), nsmall = 10)
```

```{r}
#question: Calculate the chi-square test statistic for testing whether an incident is more likely to last longer than 60 minutes when CO detector is not present.
chi_sq_data <- incidents %>% 
  select(CO_DETECTOR_PRESENT_DESC, TOTAL_INCIDENT_DURATION) %>% 
  filter(!is.na(CO_DETECTOR_PRESENT_DESC)) %>% 
  mutate(incident_duration_less_than_60 = ifelse(TOTAL_INCIDENT_DURATION/60 < 60, "Yes", "No")) %>% 
  select(CO_DETECTOR_PRESENT_DESC, incident_duration_less_than_60)

#chi-square test: null hypothesis: co-detector absent and incident duration greater than 60 are completely independant
#alternate hypothesis: when co-detector is absent then incident duration is likely to be greater than 60 minutes

# Yate's correction is used to avoid overestimation of statistical significance of small data but we have ample data points so let's set it to false and apply chi-square test.
chisq.test(chi_sq_data$CO_DETECTOR_PRESENT_DESC, chi_sq_data$incident_duration_less_than_60, correct = FALSE)

format(round(chisq.test(chi_sq_data$CO_DETECTOR_PRESENT_DESC, chi_sq_data$incident_duration_less_than_60, correct = FALSE)$statistic,10),nsmall = 6)

#By looking at X-squared = 1171.3 and  p-value < 2.2e-16, since p value is very less, we reject null hypothesis. It means when co-detector is absent then incident duration is likely to be greater than 60 minutes
```



#Section 2
```{r}

#Question: What is the expected value of A when N=10, M=5, and T=20 ?
# positions = 10
# cars = 5
# rounds = 20

#let's create 5 different vectors to store positions for car 1 to 5
car1 <- vector(mode = "integer", length =20)
car2 <- vector(mode = "integer", length =20)
car3 <- vector(mode = "integer", length =20)
car4 <- vector(mode = "integer", length =20)
car5 <- vector(mode = "integer", length =20)

#let's assign initial positions to all 5 cars
car5[1] <- 4
car4[1] <- 3
car3[1] <- 2
car2[1] <- 1
car1[1] <- 0

#update car5 positions in each round until it reaches position 20
i <- 2
while (car5[i-1]<10) {
  car5[i] <- i + 3
  i = i +1
}

car5 <- replace(car5,car5==0,10)

#update car4 positions if car5 has reached 10 position (these can be updated till 9 since car5 is at 10)
for (i in 2:20) {
  ifelse(car5[i-1] == 10, car4[i] <- car4[i-1] + 1, car4[i] <- car4[1])
}

#update car3 positions if car4 has reached 19 position (these can be updated till 8 since car4 will be at 9)
for (i in 2:20) {
  ifelse(car4[i-1] == 9, car3[i] <- car3[i-1] + 1, car3[i] <- car3[1])
}

#update car2 positions if car3 has reached 18 position (these can be updated till 7 since car3 will be at 8)
for (i in 2:20) {
  ifelse(car3[i-1] == 8, car2[i] <- car2[i-1] + 1, car2[i] <- car2[1])
}

#update car1 positions if car2 has reached 17 position (these can be updated till 6 since car2 will be at 7)
for (i in 2:20) {
  ifelse(car2[i-1] == 7, car1[i] <- car1[i-1] + 1, car1[i] <- car1[1])
}

#Car positions
car5
car4
car3
car2
car1

car_positions <- cbind.data.frame(car1, car2, car3, car4, car5)

#Let's calculcate average (A) for all positions of car 1 to 5
avg_car1 <- mean(car_positions$car1)
avg_car2 <- mean(car_positions$car2)
avg_car3 <- mean(car_positions$car3)
avg_car4 <- mean(car_positions$car4)
avg_car5 <- mean(car_positions$car5)

probabilty_val <- 0.2 #since equal probability is assigned to each

expected_val_avg <- avg_car1 * probabilty_val + avg_car2 * probabilty_val + avg_car3 * probabilty_val + avg_car4 * probabilty_val + avg_car5 * probabilty_val

format(round(expected_val_avg,10), nsmall = 9)

#Question: What is the expected value of S when N=10, M=5, and T=20 ?
#Let's calculcate standard deviation (S) for all positions of car 1 to 5
std_dev1 <- sd(car_positions$car1)
std_dev2 <- sd(car_positions$car2)
std_dev3 <- sd(car_positions$car3)
std_dev4 <- sd(car_positions$car4)
std_dev5 <- sd(car_positions$car5)

expected_val_std_dev <- std_dev1 * probabilty_val + std_dev2 * probabilty_val + std_dev3 * probabilty_val + std_dev4 * probabilty_val + std_dev5 * probabilty_val

format(round(expected_val_std_dev,10), nsmall = 9)


#Question: What is the standard deviation of A when N=10, M=5, and T=20?
format(round(sd(c(avg_car1, avg_car2, avg_car3, avg_car4, avg_car5)),10), nsmall = 9)

#Question: What is the standard deviation of S when N=10, M=5, and T=20?
format(round(sd(c(std_dev1, std_dev2, std_dev3, std_dev4, std_dev5)),10), nsmall = 9)
```

```{r}
#Question: What is the expected value of A when N=25, M=10, and T=50 ?
#here _2 in nomination of variable is done to indicate second set of cars for part 2 of section 2
#positions = 25
#cars = 10
#rounds = 50

#let's create 5 different vectors to store positions for car 1 to 10
car1_2 <- vector(mode = "integer", length =50)
car2_2 <- vector(mode = "integer", length =50)
car3_2 <- vector(mode = "integer", length =50)
car4_2 <- vector(mode = "integer", length =50)
car5_2 <- vector(mode = "integer", length =50)
car6_2 <- vector(mode = "integer", length =50)
car7_2 <- vector(mode = "integer", length =50)
car8_2 <- vector(mode = "integer", length =50)
car9_2 <- vector(mode = "integer", length =50)
car10_2 <- vector(mode = "integer", length =50)


#let's assign initial positions to all 5 cars
car10_2[1] <- 9
car9_2[1] <- 8
car8_2[1] <- 7
car7_2[1] <- 6
car6_2[1] <- 5
car5_2[1] <- 4
car4_2[1] <- 3
car3_2[1] <- 2
car2_2[1] <- 1
car1_2[1] <- 0

#update car10_2 positions in each round until it reaches position 25
i <- 2
while(car10_2[i-1]< 25) {
  car10_2[i] <- i + 8
  i = i +1
}

car10_2 <- replace(car10_2,car10_2==0,25)

#update car9_2 positions if car10_2 has reached 25 position (these can be updated till 24 since car10_2 is at 25 at end of possible rounds to move forward)
for (i in 2:50) {
  ifelse(car10_2[i-1] == 25,  ifelse(car9_2[i-1] == 24, car9_2[i] <- 24, car9_2[i] <- car9_2[i-1] + 1), car9_2[i] <- car9_2[1])
}

#update car8_2 positions if car9_2 has reached 24 position (these can be updated till 23 since car9_2 will possibly be at 24 at end of rounds)
for (i in 2:50) {
  ifelse(car9_2[i-1] == 24, ifelse(car8_2[i-1] == 23, car8_2[i] <- 23, car8_2[i] <- car8_2[i-1] + 1), car8_2[i] <- car8_2[1])
}

#update car7_2 positions if car8_2 has reached 23 position (these can be updated till 22 since car8_2 will possibly be at 23 at end of rounds)
for (i in 2:50) {
  ifelse(car8_2[i-1] == 23, ifelse(car7_2[i-1] == 22, car7_2[i] <- 22, car7_2[i] <- car7_2[i-1] + 1), car7_2[i] <- car7_2[1])
}

#update car6_2 positions if car7_2 has reached 22 position (these can be updated till 21 since car7_2 will possibly be at 22 at end of rounds)
for (i in 2:50) {
  ifelse(car7_2[i-1] == 22, ifelse(car6_2[i-1] == 21, car6_2[i] <- 21, car6_2[i] <- car6_2[i-1] + 1), car6_2[i] <- car6_2[1])
}

#update car5_2 positions if car6_2 has reached 21 position (these can be updated till 20 since car6_2 will possibly be at 21 at end of rounds)
for (i in 2:50) {
  ifelse(car6_2[i-1] == 21, ifelse(car5_2[i-1] == 20, car5_2[i] <- 20, car5_2[i] <- car5_2[i-1] + 1), car5_2[i] <- car5_2[1])
}

#update car4_2 positions if car5_2 has reached 20 position (these can be updated till 19 since car5_2 will possibly be at 20 at end of rounds)
for (i in 2:50) {
  ifelse(car5_2[i-1] == 20, ifelse(car4_2[i-1] == 19, car4_2[i] <- 19, car4_2[i] <- car4_2[i-1] + 1), car4_2[i] <- car4_2[1])
}


#update car3_2 positions if car4_2 has reached  19 position (these can be updated till 18 since car4_2 will possibly be at 19 at end of rounds)
for (i in 2:50) {
  ifelse(car4_2[i-1] == 19, ifelse(car3_2[i-1] == 18, car3_2[i] <- 18, car3_2[i] <- car3_2[i-1] + 1), car3_2[i] <- car3_2[1])
}


#update car2_2 positions if car5_2 has reached 18 position (these can be updated till 17 since car3_2 will possibly be at 18 at end of rounds)
for (i in 2:50) {
  ifelse(car3_2[i-1] == 18, ifelse(car2_2[i-1] == 17, car2_2[i] <- 17, car2_2[i] <- car2_2[i-1] + 1), car2_2[i] <- car2_2[1])
}


#update car1_2 positions if car5_2 has reached 17 position (these can be updated till 16 since car2_2 will possibly be at 17 at end of rounds)
for (i in 2:50) {
  ifelse(car2_2[i-1] == 17, ifelse(car1_2[i-1] == 16, car1_2[i] <- 16, car1_2[i] <- car1_2[i-1] + 1), car1_2[i] <- car1_2[1])
}


#Car positions
car10_2
car9_2
car8_2
car7_2
car6_2
car5_2
car4_2
car3_2
car2_2
car1_2


car_positions_2 <- cbind.data.frame(car1_2, car2_2, car3_2, car4_2, car5_2, car6_2, car7_2, car8_2, car9_2, car10_2)

#Let's calculcate average (A) for all positions of car 1 to 5
avg_car1_2 <- mean(car_positions_2$car1_2)
avg_car2_2 <- mean(car_positions_2$car2_2)
avg_car3_2 <- mean(car_positions_2$car3_2)
avg_car4_2 <- mean(car_positions_2$car4_2)
avg_car5_2 <- mean(car_positions_2$car5_2)
avg_car6_2 <- mean(car_positions_2$car6_2)
avg_car7_2 <- mean(car_positions_2$car7_2)
avg_car8_2 <- mean(car_positions_2$car8_2)
avg_car9_2 <- mean(car_positions_2$car9_2)
avg_car10_2 <- mean(car_positions_2$car10_2)

probabilty_val_2 <- 1/10 #since equal probability is assigned to each

expected_val_avg_2 <- avg_car1_2 * probabilty_val_2 + avg_car2_2 * probabilty_val_2 + avg_car3_2 * probabilty_val_2 + avg_car4_2 * probabilty_val_2 + avg_car5_2 * probabilty_val_2 + avg_car6_2 * probabilty_val_2 + avg_car7_2 * probabilty_val_2 + avg_car8_2 * probabilty_val_2 + avg_car9_2 * probabilty_val_2 + avg_car10_2 * probabilty_val_2

format(round(expected_val_avg_2,10), nsmall = 9)

#Question: What is the expected value of S when N=25, M=10, and T=50 ?
#Let's calculcate standard deviation (S) for all positions of car 1 to 10
std_dev1_2 <- sd(car_positions_2$car1_2)
std_dev2_2 <- sd(car_positions_2$car2_2)
std_dev3_2 <- sd(car_positions_2$car3_2)
std_dev4_2 <- sd(car_positions_2$car4_2)
std_dev5_2 <- sd(car_positions_2$car5_2)
std_dev6_2 <- sd(car_positions_2$car6_2)
std_dev7_2 <- sd(car_positions_2$car7_2)
std_dev8_2 <- sd(car_positions_2$car8_2)
std_dev9_2 <- sd(car_positions_2$car9_2)
std_dev10_2 <- sd(car_positions_2$car10_2)

expected_val_std_dev_2 <- std_dev1_2 * probabilty_val_2 + std_dev2_2 * probabilty_val_2 + std_dev3_2 * probabilty_val_2 + std_dev4_2 * probabilty_val_2 + std_dev5_2 * probabilty_val_2 + std_dev6_2 * probabilty_val_2 + std_dev7_2 * probabilty_val_2 + std_dev8_2 * probabilty_val_2 + std_dev9_2 * probabilty_val_2 +  std_dev10_2 * probabilty_val_2

format(round(expected_val_std_dev_2,10), nsmall = 9)


#Question: What is the standard deviation of A when N=25, M=10, and T=50?
format(round(sd(c(avg_car1_2, avg_car2_2, avg_car3_2, avg_car4_2, avg_car5_2, avg_car6_2,avg_car7_2,avg_car8_2,avg_car9_2,avg_car10_2)),10), nsmall = 9)

#Question: What is the standard deviation of S when N=25, M=10, and T=50?
format(round(sd(c(std_dev1_2, std_dev2_2, std_dev3_2, std_dev4_2, std_dev5_2, std_dev6_2, std_dev7_2, std_dev8_2, std_dev9_2, std_dev10_2)),10), nsmall = 9)
```

#Section 3
```{r}
#Read boston crime data
crime_data_boston <- read_csv("crime.csv")

#Check if data is loaded properly
head(crime_data_boston)
```
```{r}
#let's do exploratory data analysis
library(tidyverse)

#Plot information about what crimes are most frequently occuring in Boston.This will help law inforcement as well as community supoort group to divert or allocate type of resources.
crime_data_boston %>% 
  select(OFFENSE_CODE_GROUP, DAY_OF_WEEK) %>% 
  group_by(OFFENSE_CODE_GROUP) %>%
  filter(OFFENSE_CODE_GROUP != "Other") %>% 
  summarise(crime_frequency = n()) %>% 
  arrange(desc(crime_frequency)) %>% 
  head(10) %>% 
  ggplot(aes(x = reorder(OFFENSE_CODE_GROUP, desc(crime_frequency)), y = crime_frequency)) +
  geom_col(fill = "orange", color = "black") +
  ggtitle("Most frequently committed crimes in Boston") +
  labs(x = "Crime Type", y = "Crime Frequency", caption = "Data Source: https://www.kaggle.com, 1k = 1000 records") +
  geom_label(aes(x = OFFENSE_CODE_GROUP, y = crime_frequency, label = paste(round(crime_frequency/1000, digits = 2), "k")))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

```

```{r}
#Let's find out the areas where most crimes are committed in Boston.
crime_data_boston %>% 
  select(STREET) %>% 
  group_by(STREET) %>%
  filter(STREET != "NA") %>% 
  summarise(crime_frequency = n()) %>%
  arrange(desc(crime_frequency)) %>% 
  head(10) %>% 
  ggplot(aes(x = reorder(STREET, crime_frequency), y = crime_frequency)) +
  geom_bar(stat = "identity",fill = "orange", color = "black", position = "dodge") +
  coord_flip() +
  geom_label(aes(x = STREET, y = crime_frequency, label = paste(round(crime_frequency/1000, digits = 2), "k"))) +
  ggtitle("Areas where crimes happens most in Boston") +
  labs(x = "Area Name", y = "Crime Frequency", caption = "Data Source: https://www.kaggle.com, 1k = 1000 records")


```




